import threading
import time
import logging
from pathlib import Path
import re
import sys
import sympy as sp
from sympy import simplify
from sympy.parsing.sympy_parser import parse_expr

# Colores
ESC = "\033["
RESET = ESC + "0m"
B = ESC + "36m"      # Cian para tiempos
G = ESC + "1;32m"    # Verde claro para números
Y = ESC + "1;33m"
R = ESC + "1;31m"
GREY = "\x1b[37;20m" # Gris suave

# Formatter Gris
class GreyFormatter(logging.Formatter):
    BASE_FMT = f"{GREY}%(asctime)s [%(threadName)s] %(message)s{RESET}"
    DATE_FMT = "%Y-%m-%d %H:%M:%S"

    def format(self, record):
        formatter = logging.Formatter(self.BASE_FMT, datefmt=self.DATE_FMT)
        return formatter.format(record)

# Configurar logging (reemplaza basicConfig)
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Limpiar handlers previos
for handler in logger.handlers[:]:
    logger.removeHandler(handler)

# Nuevo handler con gris
ch = logging.StreamHandler()
ch.setLevel(logging.INFO)
ch.setFormatter(GreyFormatter())
logger.addHandler(ch)

# Archivos
DEMANDA = Path("demanda.txt")
OUT_INTEGRALES = Path("integrales.txt")
OUT_DERIVADAS = Path("derivadas.txt")
OUT_TESIS = Path("tesis.txt")
OUT_LARGO = Path("largo.txt")
OUT_TIEMPOS = Path("tiempos.txt") 

# Límite de hilos concurrentes
MAX_CONCURRENT = 4



# Clase BaseDeDatos
class BaseDeDatos:
    def __init__(self, max_concurrent: int):
        self.sem = threading.Semaphore(max_concurrent)
        # Locks para archivos
        self.lock_integrales = threading.Lock()
        self.lock_derivadas = threading.Lock()
        self.lock_tesis = threading.Lock()
        self.lock_largo = threading.Lock()
        self.lock_tiempos = threading.Lock()
        self.tesis_existentes = set()

def tokenizar(texto: str):
    return re.findall(r"[a-zA-ZáéíóúüñÁÉÍÓÚÜÑ0-9']+", texto.lower())

def contar_palabras(texto: str) -> int:
    return len(tokenizar(texto))

def validar_tarea(tipo: str, contenido: str):
    tipo = tipo.strip().upper()
    if tipo not in ("INTEGRAL", "DERIVADA", "TESIS"):
        return False
    if not contenido.strip():
        return False
    return True

# Tareas 
def procesar_integral(expr_txt: str):
    x = sp.symbols('x')
    try:
        expr_txt = expr_txt.replace("^", "**")  # para aceptar potencias
        expr = parse_expr(expr_txt, evaluate=True)
        integral = sp.integrate(expr, x)
        return True, str(simplify(integral)), ""
    except Exception as e:
        return False, None, str(e)

def procesar_derivada(expr_txt: str):
    x = sp.symbols('x')
    try:
        expr_txt = expr_txt.replace("^", "**") 
        expr = parse_expr(expr_txt, evaluate=True)
        deriv = sp.diff(expr, x)
        return True, str(simplify(deriv)), ""
    except Exception as e:
        return False, None, str(e)

def procesar_tesis(bd: BaseDeDatos, contenido: str, start: float):
    if contenido.startswith("FILE:"):
        ruta = Path(contenido[5:].strip())
        try:
            texto = ruta.read_text(encoding="utf-8", errors="ignore").strip()
        except Exception as e:
            logging.error(f"{R}No se puede leer la tesis desde archivo {ruta}: {e}")
            texto = f"[ERROR leyendo {ruta} : {e}]"
    else:
        texto = contenido.strip()

    # Registrar tesis si no es duplicada
    with bd.lock_tesis:
        if texto not in bd.tesis_existentes:
            bd.tesis_existentes.add(texto)
            with OUT_TESIS.open("a", encoding="utf-8") as f:
                f.write("\nTESIS AGREGADA:\n" + texto + "\n")
            
            # Conteo de palabras solo si no es duplicada
            n_palabras = contar_palabras(texto)

            # Actualizar contador de palabras total
            with bd.lock_largo:
                try:
                    cur_val = int(OUT_LARGO.read_text(encoding="utf-8").strip() or "0")
                except ValueError:
                    cur_val = 0
                nuevo_total = cur_val + n_palabras
                OUT_LARGO.write_text(str(nuevo_total) + "\n", encoding="utf-8")
        else:
            logging.info("Tesis duplicada, no se agrega nuevamente.")
            n_palabras = 0
            nuevo_total = None
            
    return n_palabras, nuevo_total


def registrar_tiempo(bd: BaseDeDatos, tarea_tipo: str, contenido: str, inicio: float, fin: float):
    dt = fin - inicio
    linea = f"{time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(fin))} | {tarea_tipo}  | Duración: {dt:.6f}s | Contenido: {contenido[:50]}\n"
    with bd.lock_tiempos:
        with OUT_TIEMPOS.open("a", encoding="utf-8") as f:
            f.write(linea)
            
# Worker que procesa una tarea individual
def procesar_tarea(bd: BaseDeDatos, tarea_tipo: str, contenido: str):

    if not validar_tarea(tarea_tipo, contenido):
        logging.info(f"Tarea inválida ignorada: {tarea_tipo} | {contenido[:50]}")
        return

    bd.sem.acquire()
    start = time.time()

    try:
        if tarea_tipo == "INTEGRAL":
            ok, res, err = procesar_integral(contenido)
            dt = time.time() - start
            if ok:
                linea = f"∫({contenido}) dx = {res}\n"
            else:
                linea = f"ERROR ∫({contenido}) -> {err}\n"

            with bd.lock_integrales:
                with OUT_INTEGRALES.open("a", encoding="utf-8") as f:
                    f.write(linea)
            logging.info(f"{RESET}Integral procesada: [{Y}{contenido}{RESET}] | (t = {B}{dt:.6f}s{RESET})")

        elif tarea_tipo == "DERIVADA":
            ok, res, err = procesar_derivada(contenido)
            dt = time.time() - start
            if ok:
                linea = f"d/dx({contenido}) = {res}\n"
            else:
                linea = f"ERROR d/dx({contenido}) -> {err}\n"

            with bd.lock_derivadas:
                with OUT_DERIVADAS.open("a", encoding="utf-8") as f:
                    f.write(linea)
            logging.info(f"{RESET}Derivada procesada: [{Y}{contenido}{RESET}] | (t = {B}{dt:.6f}s{RESET}) ")
        elif tarea_tipo == "TESIS":
            n_palabras, nuevo_total = procesar_tesis(bd, contenido, start)
            dt = time.time() - start
            preview = contenido[:100] + ("..." if len(contenido) > 100 else "")
            logging.info(
                f"\n{RESET}Tesis procesada: {preview}... | (palabras = {G}{n_palabras}{RESET}, total = {G}{nuevo_total}{RESET}, t = {B}{dt:.6f}s{RESET}) \n"
            )

        registrar_tiempo(bd, tarea_tipo, contenido, start, time.time())

    finally:
        bd.sem.release()
        
        
# Lectura de demanda
def leer_demanda(path: Path):
    tareas = []
    if not path.exists():
        raise FileNotFoundError(f"No se encontrò {path.resolve()}")

    with path.open("r", encoding="utf-8", errors="ignore") as f:
        for ln in f:
            ln = ln.strip()
            if not ln or ln.startswith("#"):
                continue
            tipo = None
            contenido = None
            # Detectar separador: puede ser "|" o espacio
            if "|" in ln:
                tipo, contenido = ln.split("|", 1)
            else:
                partes = ln.split(maxsplit=1)
                if len(partes) == 2:
                    tipo, contenido = partes

            if tipo is None or contenido is None:
                logging.warning(f"Línea ignorada (Formato inválido/separador no encontrado): {ln[:70]}...")
                continue

            tipo = tipo.strip().upper()
            contenido = contenido.strip()

            if not validar_tarea(tipo, contenido):
                logging.warning(f"Línea ignorada (Tipo/Contenido inválido): TIPO='{tipo}' | CONTENIDO='{contenido[:50]}...'")
                continue
            
            tareas.append((tipo, contenido))
            
    return tareas

# Procesamiento de lista de tareas (con hilos)
def procesar_tareas_concurrentes(tareas, max_concurrent=4):
    bd = BaseDeDatos(max_concurrent=max_concurrent)
    threads = []
    tareas_ok = 0

    for i, (tipo, contenido) in enumerate(tareas, start=1):
        t = threading.Thread(target=procesar_tarea, args=(bd, tipo, contenido), name=f"Worker-{i}")
        threads.append(t)
        tareas_ok += 1
        t.start()

    for t in threads:
        t.join()

    return tareas_ok

def main():
    logging.info("Inicio del procesador de tareas\n")
    # Reinicia los archivos para que no solo se agreguen a los resultados anterirores
    OUT_LARGO.write_text("0\n", encoding="utf-8")
    OUT_TESIS.write_text("", encoding="utf-8")
    OUT_TIEMPOS.write_text("", encoding="utf-8") 
    OUT_INTEGRALES.write_text("", encoding="utf-8")
    OUT_DERIVADAS.write_text("", encoding="utf-8")
        
    try:
        tareas = leer_demanda(DEMANDA)
    except Exception as e:
        logging.error(f"{R}Error leyendo demanda: {e}")
        sys.exit(1)

    t0 = time.time()
    tareas_ok = procesar_tareas_concurrentes(tareas, max_concurrent=MAX_CONCURRENT)
    dt = time.time() - t0
    
    total_palabras = int(OUT_LARGO.read_text(encoding="utf-8").strip() or "0")
    
    logging.info(f"\n{RESET}Fin del procesador de tareas\n")
    logging.info(f"\n{RESET}Total de tareas procesadas correctamente: {G}{tareas_ok}{RESET}")
    logging.info(f"{RESET}Total de palabras procesadas en tesis: {G}{total_palabras}{RESET}")
    logging.info(f"{RESET}Procesamiento finalizado en {B} {dt:.6f}s{RESET}")
    logging.info(f"{RESET}Archivos generados: \n{OUT_INTEGRALES.resolve()}, \n{OUT_DERIVADAS.resolve()}, \n{OUT_TESIS.resolve()}, \n{OUT_LARGO.resolve()}, \n{OUT_TIEMPOS.resolve()}")

if __name__ == "__main__":
    main()
